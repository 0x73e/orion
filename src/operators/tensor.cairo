mod core;
mod helpers;
// mod math;
// mod linalg;
// mod quantization;
// mod implementations;

// use orion::operators::tensor::core::{Tensor, TensorSerde, TensorTrait};

// use orion::operators::tensor::implementations::tensor_fp8x23::{
//     Tensor_fp8x23, FP8x23TensorAdd, FP8x23TensorSub, FP8x23TensorMul, FP8x23TensorDiv,
//     FP8x23TensorPartialEq,
// };

// use orion::operators::tensor::implementations::tensor_fp16x16::{
//     Tensor_fp16x16, FP16x16TensorAdd, FP16x16TensorSub, FP16x16TensorMul, FP16x16TensorDiv,
//     FP16x16TensorPartialEq,
// };

// use orion::operators::tensor::implementations::tensor_i8_fp8x23::{
//     Tensor_i8_fp8x23, i8TensorAdd as i8FP8x23TensorAdd, i8TensorSub as i8FP8x23Sub,
//     i8TensorMul as i8FP8x23Mul, i8TensorDiv as i8FP8x23Div,
//     TensorI8IntoTensorI32 as TensorI8FP8x23IntoTensorI32,
//     TensorI8IntoTensorFP8x23 as TensorI8FP8x23IntoTensorFP8x23,
// };

// use orion::operators::tensor::implementations::tensor_i8_fp16x16::{
//     Tensor_i8_fp16x16, i8TensorAdd as i8FP16x16TensorAdd, i8TensorSub as i8FP16x16Sub,
//     i8TensorMul as i8FP16x16Mul, i8TensorDiv as i8FP16x16Div,
//     TensorI8IntoTensorI32 as TensorI8FP16x16IntoTensorI32,
//     TensorI8IntoTensorFP16x16 as TensorI8FP16x16IntoTensorFP16x16,
// };

// use orion::operators::tensor::implementations::tensor_i32_fp8x23::{
//     Tensor_i32_fp8x23, i32TensorAdd as i32FP8x23TensorAdd, i32TensorSub as i32FP8x23Sub,
//     i32TensorMul as i32FP8x23Mul, i32TensorDiv as i32FP8x23Div,
// };

// use orion::operators::tensor::implementations::tensor_i32_fp16x16::{
//     Tensor_i32_fp16x16, i32TensorAdd as i32FP16x16TensorAdd, i32TensorSub as i32FP16x16Sub,
//     i32TensorMul as i32FP16x16Mul, i32TensorDiv as i32FP16x16Div,
// };

// use orion::operators::tensor::implementations::tensor_u32_fp8x23::{
//     Tensor_u32_fp8x23, u32TensorAdd as u32FP8x23TensorAdd, u32TensorSub as u32FP8x23Sub,
//     u32TensorMul as u32FP8x23Mul, u32TensorDiv as u32FP8x23Div,
// };

// use orion::operators::tensor::implementations::tensor_u32_fp16x16::{
//     Tensor_u32_fp16x16, u32TensorAdd as u32FP16x16TensorAdd, u32TensorSub as u32FP16x16Sub,
//     u32TensorMul as u32FP16x16Mul, u32TensorDiv as u32FP16x16Div,
// };
